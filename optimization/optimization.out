\BOOKMARK [0][-]{section*.1}{Contents}{}
\BOOKMARK [-1][-]{part.1}{Themes}{}
\BOOKMARK [0][-]{chapter.1}{Solver design}{part.1}
\BOOKMARK [0][-]{chapter.2}{Applications of Constrained optimization}{part.1}
\BOOKMARK [-1][-]{part.2}{Problem structure}{}
\BOOKMARK [0][-]{chapter.3}{The problem}{part.2}
\BOOKMARK [1][-]{section.3.1}{Standard \(primal\) form}{chapter.3}
\BOOKMARK [2][-]{subsection.3.1.1}{Explicit constraints}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.2}{Implicit constraints}{section.3.1}
\BOOKMARK [2][-]{subsection.3.1.3}{Optimal value}{section.3.1}
\BOOKMARK [1][-]{section.3.2}{Equivalent formulations}{chapter.3}
\BOOKMARK [2][-]{subsection.3.2.1}{Epigraph formulation}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.2}{Linear equiality constraints}{section.3.2}
\BOOKMARK [2][-]{subsection.3.2.3}{Augmented/ Slack form}{section.3.2}
\BOOKMARK [1][-]{section.3.3}{Conic \(in\)equalities constraints}{chapter.3}
\BOOKMARK [1][-]{section.3.4}{Special cases}{chapter.3}
\BOOKMARK [2][-]{subsection.3.4.1}{Feasibility problem}{section.3.4}
\BOOKMARK [1][-]{section.3.5}{Perturbed problem}{chapter.3}
\BOOKMARK [0][-]{chapter.4}{The solution}{part.2}
\BOOKMARK [1][-]{section.4.1}{Feasible region}{chapter.4}
\BOOKMARK [2][-]{subsection.4.1.1}{Active, inactive constraints at x}{section.4.1}
\BOOKMARK [3][-]{subsubsection.4.1.1.1}{Strict feasibility}{subsection.4.1.1}
\BOOKMARK [2][-]{subsection.4.1.2}{Active constraints and their gradient}{section.4.1}
\BOOKMARK [3][-]{subsubsection.4.1.2.1}{Constraint surface, gradient}{subsection.4.1.2}
\BOOKMARK [3][-]{subsubsection.4.1.2.2}{Direction of the gradient}{subsection.4.1.2}
\BOOKMARK [3][-]{subsubsection.4.1.2.3}{Intersection of constraint surfaces}{subsection.4.1.2}
\BOOKMARK [1][-]{section.4.2}{Optimality criteria}{chapter.4}
\BOOKMARK [2][-]{subsection.4.2.1}{Optimal x}{section.4.2}
\BOOKMARK [2][-]{subsection.4.2.2}{Connection with gradient}{section.4.2}
\BOOKMARK [2][-]{subsection.4.2.3}{Unconstrained fn}{section.4.2}
\BOOKMARK [3][-]{subsubsection.4.2.3.1}{Differentiable f}{subsection.4.2.3}
\BOOKMARK [3][-]{subsubsection.4.2.3.2}{Local extreme point}{subsection.4.2.3}
\BOOKMARK [3][-]{subsubsection.4.2.3.3}{Extension to convex non-differentiable f}{subsection.4.2.3}
\BOOKMARK [2][-]{subsection.4.2.4}{Gradient of objective, the active constraint surface}{section.4.2}
\BOOKMARK [3][-]{subsubsection.4.2.4.1}{Direction in case of active ineq constraints}{subsection.4.2.4}
\BOOKMARK [3][-]{subsubsection.4.2.4.2}{General condition}{subsection.4.2.4}
\BOOKMARK [3][-]{subsubsection.4.2.4.3}{Optimality in special cases}{subsection.4.2.4}
\BOOKMARK [2][-]{subsection.4.2.5}{Sufficiency for local optima}{section.4.2}
\BOOKMARK [2][-]{subsection.4.2.6}{Conic inequality constrained problems}{section.4.2}
\BOOKMARK [1][-]{section.4.3}{General strategies}{chapter.4}
\BOOKMARK [2][-]{subsection.4.3.1}{Hardness of finding global optimum}{section.4.3}
\BOOKMARK [2][-]{subsection.4.3.2}{Bisection method: using feasability solvers}{section.4.3}
\BOOKMARK [0][-]{chapter.5}{Constraints in the objective}{part.2}
\BOOKMARK [1][-]{section.5.1}{Constrained and unconstrained formulations: equivalence}{chapter.5}
\BOOKMARK [2][-]{subsection.5.1.1}{Lagrangian functional}{section.5.1}
\BOOKMARK [3][-]{subsubsection.5.1.1.1}{Definition motivations}{subsection.5.1.1}
\BOOKMARK [2][-]{subsection.5.1.2}{Unconstrained program from constrained problem}{section.5.1}
\BOOKMARK [3][-]{subsubsection.5.1.2.1}{Objective - constraint tradeoff}{subsection.5.1.2}
\BOOKMARK [2][-]{subsection.5.1.3}{Lagrangian multipliers and tightness of constraints}{section.5.1}
\BOOKMARK [2][-]{subsection.5.1.4}{Constrained program from unconstrained problem}{section.5.1}
\BOOKMARK [0][-]{chapter.6}{Dual problem}{part.2}
\BOOKMARK [1][-]{section.6.1}{Dual functional}{chapter.6}
\BOOKMARK [2][-]{subsection.6.1.1}{Definition}{section.6.1}
\BOOKMARK [3][-]{subsubsection.6.1.1.1}{Uniqueness}{subsection.6.1.1}
\BOOKMARK [2][-]{subsection.6.1.2}{Connection with conjugate of the objective}{section.6.1}
\BOOKMARK [3][-]{subsubsection.6.1.2.1}{Linear constraints case}{subsection.6.1.2}
\BOOKMARK [2][-]{subsection.6.1.3}{As intercepts of supporting hyperplane to an image of the domain}{section.6.1}
\BOOKMARK [3][-]{subsubsection.6.1.3.1}{Epigraph view}{subsection.6.1.3}
\BOOKMARK [2][-]{subsection.6.1.4}{For perturbed problem}{section.6.1}
\BOOKMARK [2][-]{subsection.6.1.5}{Lower bounds on solution to the primal}{section.6.1}
\BOOKMARK [1][-]{section.6.2}{Convex Dual problem}{chapter.6}
\BOOKMARK [2][-]{subsection.6.2.1}{Picking the right primal}{section.6.2}
\BOOKMARK [2][-]{subsection.6.2.2}{As finding top intercept of supporting hyperplane}{section.6.2}
\BOOKMARK [1][-]{section.6.3}{Duality gap b/w primal, dual solutions}{chapter.6}
\BOOKMARK [2][-]{subsection.6.3.1}{Strong duality}{section.6.3}
\BOOKMARK [2][-]{subsection.6.3.2}{Strong duality: optimality conditions}{section.6.3}
\BOOKMARK [3][-]{subsubsection.6.3.2.1}{Optimality conditions using strong duality}{subsection.6.3.2}
\BOOKMARK [3][-]{subsubsection.6.3.2.2}{Primal dual solvers}{subsection.6.3.2}
\BOOKMARK [2][-]{subsection.6.3.3}{Strong duality: Meaning of dual variables}{section.6.3}
\BOOKMARK [3][-]{subsubsection.6.3.3.1}{As weights in lagrangian form}{subsection.6.3.3}
\BOOKMARK [3][-]{subsubsection.6.3.3.2}{Sensitivity analysis}{subsection.6.3.3}
\BOOKMARK [2][-]{subsection.6.3.4}{Constraint qualifications to ensure strong duality}{section.6.3}
\BOOKMARK [0][-]{chapter.7}{Vector optimization}{part.2}
\BOOKMARK [1][-]{section.7.1}{Multicriterion optimization}{chapter.7}
\BOOKMARK [1][-]{section.7.2}{Solutions}{chapter.7}
\BOOKMARK [2][-]{subsection.7.2.1}{Optimality}{section.7.2}
\BOOKMARK [2][-]{subsection.7.2.2}{Scalarization}{section.7.2}
\BOOKMARK [2][-]{subsection.7.2.3}{Visualiztion: tradeoff curve}{section.7.2}
\BOOKMARK [0][-]{chapter.8}{Prove properties of solution}{part.2}
\BOOKMARK [1][-]{section.8.1}{Motivation, Notation}{chapter.8}
\BOOKMARK [2][-]{subsection.8.1.1}{Example}{section.8.1}
\BOOKMARK [3][-]{subsubsection.8.1.1.1}{Uniqueness}{subsection.8.1.1}
\BOOKMARK [1][-]{section.8.2}{General proof technique}{chapter.8}
\BOOKMARK [2][-]{subsection.8.2.1}{Possible computational intractability}{section.8.2}
\BOOKMARK [-1][-]{part.3}{Problem formulation, solution}{}
\BOOKMARK [0][-]{chapter.9}{Formulating the problem}{part.3}
\BOOKMARK [1][-]{section.9.1}{Focus on easily solved forms}{chapter.9}
\BOOKMARK [1][-]{section.9.2}{Dealing with strict inequality constraints}{chapter.9}
\BOOKMARK [1][-]{section.9.3}{Use equivalent formulations \(for convexity?\)}{chapter.9}
\BOOKMARK [0][-]{chapter.10}{Problem parameters}{part.3}
\BOOKMARK [1][-]{section.10.1}{Not variables}{chapter.10}
\BOOKMARK [1][-]{section.10.2}{Picking the best parameter}{chapter.10}
\BOOKMARK [2][-]{subsection.10.2.1}{Qualitative judgement}{section.10.2}
\BOOKMARK [2][-]{subsection.10.2.2}{Theoretical constraints}{section.10.2}
\BOOKMARK [0][-]{chapter.11}{Specification framework engineering}{part.3}
\BOOKMARK [-1][-]{part.4}{Linear programming}{}
\BOOKMARK [0][-]{chapter.12}{The problem}{part.4}
\BOOKMARK [1][-]{section.12.1}{Canonical form}{chapter.12}
\BOOKMARK [2][-]{subsection.12.1.1}{Nonnegative optimization form}{section.12.1}
\BOOKMARK [2][-]{subsection.12.1.2}{Equality constrained form}{section.12.1}
\BOOKMARK [1][-]{section.12.2}{Constraints and the polyhedron}{chapter.12}
\BOOKMARK [1][-]{section.12.3}{The solution}{chapter.12}
\BOOKMARK [2][-]{subsection.12.3.1}{Vertex in feasible region}{section.12.3}
\BOOKMARK [2][-]{subsection.12.3.2}{Pathological cases}{section.12.3}
\BOOKMARK [0][-]{chapter.13}{Related problems}{part.4}
\BOOKMARK [1][-]{section.13.1}{Linear fractional program}{chapter.13}
\BOOKMARK [1][-]{section.13.2}{1, infty norm approximations}{chapter.13}
\BOOKMARK [1][-]{section.13.3}{Robust linear programming}{chapter.13}
\BOOKMARK [2][-]{subsection.13.3.1}{Deterministic model}{section.13.3}
\BOOKMARK [2][-]{subsection.13.3.2}{Stochastic model}{section.13.3}
\BOOKMARK [0][-]{chapter.14}{LP Algorithms}{part.4}
\BOOKMARK [1][-]{section.14.1}{Exhaustive search alg}{chapter.14}
\BOOKMARK [1][-]{section.14.2}{Simplex method}{chapter.14}
\BOOKMARK [1][-]{section.14.3}{Interior point projective method}{chapter.14}
\BOOKMARK [-1][-]{part.5}{Convex Quadratic programming}{}
\BOOKMARK [0][-]{chapter.15}{Linear Constrained QP}{part.5}
\BOOKMARK [1][-]{section.15.1}{Visualization}{chapter.15}
\BOOKMARK [1][-]{section.15.2}{Dual problem}{chapter.15}
\BOOKMARK [0][-]{chapter.16}{Quadratically constrained QP \(QCQP\)}{part.5}
\BOOKMARK [0][-]{chapter.17}{Least squared error problem}{part.5}
\BOOKMARK [1][-]{section.17.1}{Problem}{chapter.17}
\BOOKMARK [2][-]{subsection.17.1.1}{Unregularized problem}{section.17.1}
\BOOKMARK [3][-]{subsubsection.17.1.1.1}{For the weighted least squares}{subsection.17.1.1}
\BOOKMARK [3][-]{subsubsection.17.1.1.2}{Solution}{subsection.17.1.1}
\BOOKMARK [2][-]{subsection.17.1.2}{The regularized problem}{section.17.1}
\BOOKMARK [1][-]{section.17.2}{Application}{chapter.17}
\BOOKMARK [2][-]{subsection.17.2.1}{Convex Optimization}{section.17.2}
\BOOKMARK [2][-]{subsection.17.2.2}{Other domains}{section.17.2}
\BOOKMARK [2][-]{subsection.17.2.3}{Regularized problems}{section.17.2}
\BOOKMARK [3][-]{subsubsection.17.2.3.1}{Penalties and priors}{subsection.17.2.3}
\BOOKMARK [1][-]{section.17.3}{Standard formulations}{chapter.17}
\BOOKMARK [2][-]{subsection.17.3.1}{Normalizing columns of A}{section.17.3}
\BOOKMARK [1][-]{section.17.4}{Quadratic regularizer}{chapter.17}
\BOOKMARK [2][-]{subsection.17.4.1}{The solution form}{section.17.4}
\BOOKMARK [2][-]{subsection.17.4.2}{The geometry}{section.17.4}
\BOOKMARK [2][-]{subsection.17.4.3}{Effect}{section.17.4}
\BOOKMARK [1][-]{section.17.5}{l2 and linf regularizers}{chapter.17}
\BOOKMARK [2][-]{subsection.17.5.1}{l2 regularizer}{section.17.5}
\BOOKMARK [3][-]{subsubsection.17.5.1.1}{Problem}{subsection.17.5.1}
\BOOKMARK [3][-]{subsubsection.17.5.1.2}{Solution}{subsection.17.5.1}
\BOOKMARK [3][-]{subsubsection.17.5.1.3}{Relation with Quadratic regularizer}{subsection.17.5.1}
\BOOKMARK [2][-]{subsection.17.5.2}{lInf regularizer}{section.17.5}
\BOOKMARK [1][-]{section.17.6}{Forward stepwise regression for sparsity}{chapter.17}
\BOOKMARK [2][-]{subsection.17.6.1}{Forward stagewise regression}{section.17.6}
\BOOKMARK [2][-]{subsection.17.6.2}{Least Angle Regression}{section.17.6}
\BOOKMARK [2][-]{subsection.17.6.3}{Lasso solving modification}{section.17.6}
\BOOKMARK [3][-]{subsubsection.17.6.3.1}{Reason for the fix}{subsection.17.6.3}
\BOOKMARK [1][-]{section.17.7}{0 norm regularizer: Compressed sensing}{chapter.17}
\BOOKMARK [2][-]{subsection.17.7.1}{Problem scenario}{section.17.7}
\BOOKMARK [3][-]{subsubsection.17.7.1.1}{Finding support: Combinatorial hardness}{subsection.17.7.1}
\BOOKMARK [2][-]{subsection.17.7.2}{Finding support: Target optimization problems}{section.17.7}
\BOOKMARK [2][-]{subsection.17.7.3}{Solution using 1 norm minimization}{section.17.7}
\BOOKMARK [3][-]{subsubsection.17.7.3.1}{Restricted isometry constant for s}{subsection.17.7.3}
\BOOKMARK [3][-]{subsubsection.17.7.3.2}{Incoherence/ almost orthogonality}{subsection.17.7.3}
\BOOKMARK [1][-]{section.17.8}{1 norm regularizer: Lasso}{chapter.17}
\BOOKMARK [2][-]{subsection.17.8.1}{Importance}{section.17.8}
\BOOKMARK [2][-]{subsection.17.8.2}{The geometry}{section.17.8}
\BOOKMARK [-1][-]{part.6}{Convex optimization}{}
\BOOKMARK [0][-]{chapter.18}{The problem}{part.6}
\BOOKMARK [1][-]{section.18.1}{Importance, efficient solvability}{chapter.18}
\BOOKMARK [1][-]{section.18.2}{Standard form}{chapter.18}
\BOOKMARK [1][-]{section.18.3}{Convexity of feasible region X}{chapter.18}
\BOOKMARK [2][-]{subsection.18.3.1}{Geometry}{section.18.3}
\BOOKMARK [1][-]{section.18.4}{Identifying convex opt problems}{chapter.18}
\BOOKMARK [2][-]{subsection.18.4.1}{Check Convexity of fesible regions}{section.18.4}
\BOOKMARK [3][-]{subsubsection.18.4.1.1}{Any equality constraints should be linear.}{subsection.18.4.1}
\BOOKMARK [1][-]{section.18.5}{Properties}{chapter.18}
\BOOKMARK [2][-]{subsection.18.5.1}{Local optimum is the global optimum}{section.18.5}
\BOOKMARK [2][-]{subsection.18.5.2}{Lagrangian dual functional}{section.18.5}
\BOOKMARK [2][-]{subsection.18.5.3}{Certificate of optimality with strong duality}{section.18.5}
\BOOKMARK [2][-]{subsection.18.5.4}{Bound norm of solution}{section.18.5}
\BOOKMARK [1][-]{section.18.6}{Dual problem}{chapter.18}
\BOOKMARK [2][-]{subsection.18.6.1}{Strict feasibility Constraint qualification}{section.18.6}
\BOOKMARK [3][-]{subsubsection.18.6.1.1}{From supporting hyperplanes view}{subsection.18.6.1}
\BOOKMARK [0][-]{chapter.19}{Unconstrained problems: algorithms}{part.6}
\BOOKMARK [1][-]{section.19.1}{Problem, algorithm framework}{chapter.19}
\BOOKMARK [2][-]{subsection.19.1.1}{Problem, Assumptions}{section.19.1}
\BOOKMARK [2][-]{subsection.19.1.2}{Algorithm framework}{section.19.1}
\BOOKMARK [3][-]{subsubsection.19.1.2.1}{As Iteratively solving gradient eqns}{subsection.19.1.2}
\BOOKMARK [2][-]{subsection.19.1.3}{Common assumptions}{section.19.1}
\BOOKMARK [3][-]{subsubsection.19.1.3.1}{Assumptions about f}{subsection.19.1.3}
\BOOKMARK [3][-]{subsubsection.19.1.3.2}{Initial point: Assumptions}{subsection.19.1.3}
\BOOKMARK [1][-]{section.19.2}{Descent methods}{chapter.19}
\BOOKMARK [2][-]{subsection.19.2.1}{Algorithm}{section.19.2}
\BOOKMARK [3][-]{subsubsection.19.2.1.1}{Descent direction}{subsection.19.2.1}
\BOOKMARK [2][-]{subsection.19.2.2}{Find search direction}{section.19.2}
\BOOKMARK [3][-]{subsubsection.19.2.2.1}{Search direction from optimality conditions of approximation}{subsection.19.2.2}
\BOOKMARK [2][-]{subsection.19.2.3}{Line search for t}{section.19.2}
\BOOKMARK [3][-]{subsubsection.19.2.3.1}{Restriction to a slice}{subsection.19.2.3}
\BOOKMARK [3][-]{subsubsection.19.2.3.2}{Exact line search}{subsection.19.2.3}
\BOOKMARK [3][-]{subsubsection.19.2.3.3}{Backtracking}{subsection.19.2.3}
\BOOKMARK [3][-]{subsubsection.19.2.3.4}{Arbitrary choice}{subsection.19.2.3}
\BOOKMARK [1][-]{section.19.3}{Steepest descent}{chapter.19}
\BOOKMARK [2][-]{subsection.19.3.1}{As 1st order approximation minimization}{section.19.3}
\BOOKMARK [2][-]{subsection.19.3.2}{Descent direction}{section.19.3}
\BOOKMARK [2][-]{subsection.19.3.3}{Stopping criterion}{section.19.3}
\BOOKMARK [2][-]{subsection.19.3.4}{Convergence}{section.19.3}
\BOOKMARK [2][-]{subsection.19.3.5}{Geometric view}{section.19.3}
\BOOKMARK [3][-]{subsubsection.19.3.5.1}{2-dim functional example}{subsection.19.3.5}
\BOOKMARK [3][-]{subsubsection.19.3.5.2}{Goodness for circular level set case}{subsection.19.3.5}
\BOOKMARK [3][-]{subsubsection.19.3.5.3}{Zig-zagness of path towards optimum}{subsection.19.3.5}
\BOOKMARK [3][-]{subsubsection.19.3.5.4}{Implications of choice of norm}{subsection.19.3.5}
\BOOKMARK [1][-]{section.19.4}{2nd order approximation descent}{chapter.19}
\BOOKMARK [2][-]{subsection.19.4.1}{General search direction}{section.19.4}
\BOOKMARK [2][-]{subsection.19.4.2}{Search direction from Hessian}{section.19.4}
\BOOKMARK [3][-]{subsubsection.19.4.2.1}{Solving Newton equations fast}{subsection.19.4.2}
\BOOKMARK [3][-]{subsubsection.19.4.2.2}{Correctly computing gradient and Hessian}{subsection.19.4.2}
\BOOKMARK [2][-]{subsection.19.4.3}{Geometric view}{section.19.4}
\BOOKMARK [3][-]{subsubsection.19.4.3.1}{Local approximation by ellipses}{subsection.19.4.3}
\BOOKMARK [3][-]{subsubsection.19.4.3.2}{2nd order approximation ellipses}{subsection.19.4.3}
\BOOKMARK [2][-]{subsection.19.4.4}{Affine invariance}{section.19.4}
\BOOKMARK [2][-]{subsection.19.4.5}{Stopping criterion: Affine invariant }{section.19.4}
\BOOKMARK [2][-]{subsection.19.4.6}{Speed: comparison with 1st order methods}{section.19.4}
\BOOKMARK [2][-]{subsection.19.4.7}{Convergence: classical bounds}{section.19.4}
\BOOKMARK [3][-]{subsubsection.19.4.7.1}{Assumptions}{subsection.19.4.7}
\BOOKMARK [3][-]{subsubsection.19.4.7.2}{Linear decrease phase}{subsection.19.4.7}
\BOOKMARK [3][-]{subsubsection.19.4.7.3}{Quadratically convergent phase}{subsection.19.4.7}
\BOOKMARK [3][-]{subsubsection.19.4.7.4}{Overall bounds, defects}{subsection.19.4.7}
\BOOKMARK [2][-]{subsection.19.4.8}{Convergence for self concordant functions}{section.19.4}
\BOOKMARK [1][-]{section.19.5}{Alternating minimization}{chapter.19}
\BOOKMARK [1][-]{section.19.6}{Diagnosing error in code}{chapter.19}
\BOOKMARK [2][-]{subsection.19.6.1}{Incorrect gradient computation: symptoms}{section.19.6}
\BOOKMARK [0][-]{chapter.20}{Equality constrained problems}{part.6}
\BOOKMARK [1][-]{section.20.1}{Problem, assumptions}{chapter.20}
\BOOKMARK [2][-]{subsection.20.1.1}{Common Assumptions}{section.20.1}
\BOOKMARK [1][-]{section.20.2}{Solution strategies}{chapter.20}
\BOOKMARK [2][-]{subsection.20.2.1}{Reduction to unconstrained optimization}{section.20.2}
\BOOKMARK [2][-]{subsection.20.2.2}{Search direction from optimality conditions of approximation}{section.20.2}
\BOOKMARK [2][-]{subsection.20.2.3}{Local approximation by ellipsoid}{section.20.2}
\BOOKMARK [2][-]{subsection.20.2.4}{2nd order approximation descent}{section.20.2}
\BOOKMARK [3][-]{subsubsection.20.2.4.1}{Search direction}{subsection.20.2.4}
\BOOKMARK [3][-]{subsubsection.20.2.4.2}{Line search maintains feasibility}{subsection.20.2.4}
\BOOKMARK [3][-]{subsubsection.20.2.4.3}{Affine invariant stopping criterion}{subsection.20.2.4}
\BOOKMARK [3][-]{subsubsection.20.2.4.4}{Analysis: Use Newton method on equiv unconstrained problem}{subsection.20.2.4}
\BOOKMARK [3][-]{subsubsection.20.2.4.5}{Using infeasible start}{subsection.20.2.4}
\BOOKMARK [0][-]{chapter.21}{Inequality constrained problems}{part.6}
\BOOKMARK [1][-]{section.21.1}{Barrier methods}{chapter.21}
\BOOKMARK [2][-]{subsection.21.1.1}{Make inequality constraints implicit}{section.21.1}
\BOOKMARK [3][-]{subsubsection.21.1.1.1}{Motivation using indicator fn}{subsection.21.1.1}
\BOOKMARK [3][-]{subsubsection.21.1.1.2}{Logarithmic barriers}{subsection.21.1.1}
\BOOKMARK [2][-]{subsection.21.1.2}{Optimize both distance to log barrier and f0}{section.21.1}
\BOOKMARK [3][-]{subsubsection.21.1.2.1}{Tradeoff: minimizing f0 and repulsion from barrier}{subsection.21.1.2}
\BOOKMARK [3][-]{subsubsection.21.1.2.2}{Barrier algorithm}{subsection.21.1.2}
\BOOKMARK [3][-]{subsubsection.21.1.2.3}{Interpretation using Lagrangian}{subsection.21.1.2}
\BOOKMARK [3][-]{subsubsection.21.1.2.4}{Primal, dual points on the central path}{subsection.21.1.2}
\BOOKMARK [0][-]{chapter.22}{Ideas for faster solution}{part.6}
\BOOKMARK [1][-]{section.22.1}{Solving using the dual function}{chapter.22}
\BOOKMARK [1][-]{section.22.2}{Warm start}{chapter.22}
\BOOKMARK [-1][-]{part.7}{Classes solved with convex programming}{}
\BOOKMARK [0][-]{chapter.23}{Quasiconvex optimization problem}{part.7}
\BOOKMARK [1][-]{section.23.1}{Generality of constraints}{chapter.23}
\BOOKMARK [1][-]{section.23.2}{Solution using bisection}{chapter.23}
\BOOKMARK [0][-]{chapter.24}{Second order cone program \(SOCP\)}{part.7}
\BOOKMARK [1][-]{section.24.1}{Second order cone constraints}{chapter.24}
\BOOKMARK [1][-]{section.24.2}{Generality}{chapter.24}
\BOOKMARK [0][-]{chapter.25}{Conic inequalities convex program}{part.7}
\BOOKMARK [1][-]{section.25.1}{Conic form problem}{chapter.25}
\BOOKMARK [1][-]{section.25.2}{Semidefinite programming \(SDP\)}{chapter.25}
\BOOKMARK [2][-]{subsection.25.2.1}{Generality}{section.25.2}
\BOOKMARK [2][-]{subsection.25.2.2}{Recognizing SDP's}{section.25.2}
\BOOKMARK [2][-]{subsection.25.2.3}{Examples}{section.25.2}
\BOOKMARK [2][-]{subsection.25.2.4}{Dual SDP}{section.25.2}
\BOOKMARK [0][-]{chapter.26}{Geometric programming}{part.7}
\BOOKMARK [-1][-]{part.8}{Non convex optimization}{}
\BOOKMARK [0][-]{chapter.27}{Discrete optimization problems}{part.8}
\BOOKMARK [1][-]{section.27.1}{Difficulty}{chapter.27}
\BOOKMARK [1][-]{section.27.2}{General Strategies}{chapter.27}
\BOOKMARK [2][-]{subsection.27.2.1}{Relaxation to allow continuous values}{section.27.2}
\BOOKMARK [1][-]{section.27.3}{Graph based problems}{chapter.27}
\BOOKMARK [2][-]{subsection.27.3.1}{Resource allocation}{section.27.3}
\BOOKMARK [3][-]{subsubsection.27.3.1.1}{Maximum weight matching}{subsection.27.3.1}
\BOOKMARK [0][-]{chapter.28}{Continuous variables: general strategies}{part.8}
\BOOKMARK [1][-]{section.28.1}{Convexification/ smoothing}{chapter.28}
\BOOKMARK [2][-]{subsection.28.1.1}{Dual of the dual}{section.28.1}
\BOOKMARK [2][-]{subsection.28.1.2}{Local approximation}{section.28.1}
\BOOKMARK [2][-]{subsection.28.1.3}{Smoothing}{section.28.1}
\BOOKMARK [1][-]{section.28.2}{As sampling}{chapter.28}
\BOOKMARK [2][-]{subsection.28.2.1}{Stochastic gradient descent}{section.28.2}
\BOOKMARK [3][-]{subsubsection.28.2.1.1}{Comparison with stochastic gradient descent}{subsection.28.2.1}
\BOOKMARK [2][-]{subsection.28.2.2}{Damping jitters}{section.28.2}
\BOOKMARK [2][-]{subsection.28.2.3}{Using distribution sampling techniques}{section.28.2}
\BOOKMARK [0][-]{chapter.29}{Local optimization}{part.8}
\BOOKMARK [1][-]{section.29.1}{Result}{chapter.29}
\BOOKMARK [1][-]{section.29.2}{Techniques}{chapter.29}
\BOOKMARK [-1][-]{part.9}{Discrete and Combinatorial optimization}{}
\BOOKMARK [0][-]{chapter.30}{Integer programming \(IP\)}{part.9}
\BOOKMARK [1][-]{section.30.1}{Randomized rounding}{chapter.30}
\BOOKMARK [0][-]{chapter.31}{Optimal substructure problems}{part.9}
\BOOKMARK [1][-]{section.31.1}{Applicability: Decision tree view}{chapter.31}
\BOOKMARK [2][-]{subsection.31.1.1}{Optimal substructure}{section.31.1}
\BOOKMARK [3][-]{subsubsection.31.1.1.1}{Remembering subproblems used}{subsection.31.1.1}
\BOOKMARK [2][-]{subsection.31.1.2}{Overlapping subproblems}{section.31.1}
\BOOKMARK [1][-]{section.31.2}{Top down vs Bottom up}{chapter.31}
\BOOKMARK [2][-]{subsection.31.2.1}{Top down solution}{section.31.2}
\BOOKMARK [2][-]{subsection.31.2.2}{Bottom up}{section.31.2}
\BOOKMARK [3][-]{subsubsection.31.2.2.1}{Tabular view}{subsection.31.2.2}
\BOOKMARK [2][-]{subsection.31.2.3}{Time complexity}{section.31.2}
\BOOKMARK [1][-]{section.31.3}{Examples}{chapter.31}
\BOOKMARK [0][-]{chapter.32}{Branch and bound}{part.9}
\BOOKMARK [0][-]{chapter.33}{With belief propogation}{part.9}

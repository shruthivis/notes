\documentclass[10pt]{amsart}


\input{../../macros}

%opening
\title{Cryptographic primitives based on hard learning problems: Blum, Furst, Kearns, Lipton}
\author{vishvAs vAsuki}

\begin{document}
\maketitle


\section{Depth with which this was read, progress}
4 hours ( 10 - 3 pages ).

\section{Problems}

What is the precise correspondence between hard to learn C and cryptographic primitives? Do representation independent hardness of learning results require cryptographic assumptions?

How to modify learning definitions to make hardness of learning assumption equivalent to a cryptographic assumption? How to use such assumptions to make cryptographic primitives?

\section{Motivating real life scenarios}

\section{The Model}
\subsection{Terms and Variables used}

Expansion of a pseudorandom bit generator.

$F_n$ : functions over n-dim hypercube. $F = \union F_n$. Representation scheme: $(R_n, E_n)$ where every $s \in R_n$ is r(n) sized representation of $E_n(s) \in F_n$. $(R, E) = \union \set{(R_n, E_n)}$.

Distribution over $F_n$ or $R_n: P_n$. Their ensemble is P. Distribution over $\set{0,1}^{n}: D_{n}$. Their ensemble is D.

\section{Results, methods and ideas}

\subsection{The average case model of learning}

Modify learning definitions to make hardness of learning assumption equivalent to a cryptographic assumption.

\subsubsection{Motivation}
Take a hard to learn C. There may be some alg A which learns all but a small scattered fraction of C. If hardness of learning C were a cryptographic assumption, A would be a good attacker. So, use average case model of learning.

\subsection{Learnability and Cryptographic results}

\subsubsection{Strong correspondence between hardness of learning and cryptography}

\subsubsection{Generic transformation of C hard to weakly learn in the average case model into cryptographically secure pseudorandom bit generator}

Ckt depth depends on ckt depth of c in C and ckt required for generating hard distribution.
Evidence that representation independent hardness of learning results require cryptographic assumptions. Is this truly the case?

If C hard to weakly learn in the average case model, even with mq, get pseudorandom bit generator with better expansion.

\subsubsection{If C hard to strongly learn in the average case model, get one way circuits}

Parallelism preserved: Faster one way functions imply faster key sharing protocols.

\subsubsection{If C hard to weakly learn in the average case model, get CPA secure private key crypto system}

\subsubsection{Simpler construction of pseudorandom generator using the learning parity with noise assumption}

\section{Assumptions}

\section{What could have been tried to yield equivalent results}

\section{Shortcomings of the results (Very important)}

\section{Open problems}


\section{Interesting facts and results from elsewhere}

Pseudorandom bit generators can be turned into one way functions; and vice versa. But, sometimes, these don't preserve the circuit depth. How is this done?

The learning parities with noise assumption was used by Vaikuntanathan et al to build the first IBE system which does not require bilinear maps.

\section{Comments on writing style}


\section{Questions}




\end{document}
